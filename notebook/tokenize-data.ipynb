{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gbemidebe/Documents/GitHub/SolutionTransformer\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('../')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20870, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solute</th>\n",
       "      <th>solvent</th>\n",
       "      <th>T</th>\n",
       "      <th>log_gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>CCCCCCCCCCCCCCCC</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.261365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>CCCCCCCCCCCCCCCC</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>CCCCCCCCCCCCCCCC</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.301105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC</td>\n",
       "      <td>CCCCCCCCCCCCCCCC</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.235722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC</td>\n",
       "      <td>CCCCCCCCCCCCCCCC</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.248461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  solute           solvent     T  log_gamma\n",
       "0      C  CCCCCCCCCCCCCCCC  40.0  -0.261365\n",
       "1      C  CCCCCCCCCCCCCCCC  70.0  -0.287682\n",
       "2      C  CCCCCCCCCCCCCCCC  90.0  -0.301105\n",
       "3     CC  CCCCCCCCCCCCCCCC  40.0  -0.235722\n",
       "4     CC  CCCCCCCCCCCCCCCC  70.0  -0.248461"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/processed/cleaned_Brouwer_2021.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class SmilesData:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def get_split(self, train_ratio=0.8, seed=None):\n",
    "        n = len(self.data)\n",
    "        indices = np.arange(n)\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "        train_size = int(train_ratio * n)\n",
    "        train_indices = indices[:train_size]\n",
    "        test_indices = indices[train_size:]\n",
    "        train_data = self.data.iloc[train_indices].reset_index(drop=True)\n",
    "        test_data = self.data.iloc[test_indices].reset_index(drop=True)\n",
    "        return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = SmilesData(data).get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data) / (len(train_data) + len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbemidebe/miniconda3/envs/SolutionTransformer/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer #, \n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = 'seyonec/PubChem10M_SMILES_BPE_450k'\n",
    "# load in the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['solute', 'solvent', 'T', 'log_gamma']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class Input(Dataset):\n",
    "    def __init__(self, data, tokenizer, column_names = ['solute', 'solvent', 'T', 'log_gamma']):\n",
    "        '''\n",
    "        data: pandas dataframe with columns \"solute\", \"solvent\", \"T\", \"log_gamma\n",
    "        tokenizer: tokenizer to use'''\n",
    "\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.column_names = column_names\n",
    "        self.max_length = self.max_len(column_names[0]) + self.max_len(column_names[1]) + 3 # The total character length including [CLS], [SEP], and [PAD]\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Returns the length of the dataset'''\n",
    "        return len(self.data)\n",
    "\n",
    "    def max_len(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the maximum length of the input sequence\n",
    "        \"\"\"\n",
    "        return max([len(x) for x in self.data[idx]])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the input data as a dictionary with keys \"solute\", \"solvent\", \"input_ids\", \"attention_mask\", \"Temp\", and \"label\"\n",
    "        \"\"\"\n",
    "        solute = self.data.iloc[idx][self.column_names[0]]\n",
    "        solvent = self.data.iloc[idx][self.column_names[0]]\n",
    "        inputs = self.tokenizer(solute, solvent, return_tensors=\"pt\", padding='max_length', truncation=True,\n",
    "                                max_length=self.max_length)\n",
    "        \n",
    "        sample = {\n",
    "                    'solute': solute,\n",
    "                    'solvent': solvent,\n",
    "                    'input_ids': inputs[\"input_ids\"].squeeze(0),\n",
    "                    'attention_mask': inputs[\"attention_mask\"].squeeze(0),\n",
    "                    'Temp': torch.tensor(self.data.iloc[idx][self.column_names[2]], dtype=torch.float).unsqueeze(0),\n",
    "                    'label': torch.tensor(self.data.iloc[idx][self.column_names[3]], dtype=torch.float).unsqueeze(0)\n",
    "                    }\n",
    "        return sample\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = Input(train_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solute': 'CCCCCC',\n",
       " 'solvent': 'CCCCCC',\n",
       " 'input_ids': tensor([  0, 329,   2,   2, 329,   2,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'Temp': tensor([70.]),\n",
       " 'label': tensor([-0.1439])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData = Input(test_data, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solute': 'CCCC(C)C',\n",
       " 'solvent': 'CCCC(C)C',\n",
       " 'input_ids': tensor([  0, 273,  12,  39,  13,  39,   2,   2, 273,  12,  39,  13,  39,   2,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'Temp': tensor([53.2000]),\n",
       " 'label': tensor([-0.0845])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MatML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
